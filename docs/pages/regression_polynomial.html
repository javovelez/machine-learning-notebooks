<!DOCTYPE html>
<html>
  <head>
    <!-- ! custom meta tags -->
    <title>Polynomial Regression</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="author" content="Diego Inácio" />
    <meta
      property="og:url"
      content="https://diegoinacio.github.io/machine-learning-notebooks/pages/regression_polynomial.html"
    />
    <meta
      name="title"
      property="og:title"
      content="Polynomial Regression >> Machine Learning Notebooks | Diego Inácio"
    />
    <meta
      name="description"
      property="og:description"
      content="Overview and implementation of Polynomial Regression analysis."
    />
    <meta
      name="image"
      property="og:image"
      content="../images/thumb_regression_polynomial.jpg"
    />
    <meta property="og:image:type" content="image/jpeg" />
    <meta property="og:type" content="article" />
    <meta property="article:author" content="Diego Inácio" />
    <meta property="article:section" content="Machine Learning Notebooks" />
    <!-- /! custom meta tags -->
    <!-- ! custom notebook style -->
    <link rel="stylesheet" href="../assets/css/notebook.css" />
    <!-- /! custom notebook style -->

    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

    <!-- Custom stylesheet, it must be in the same directory as the html file -->
    <link rel="stylesheet" href="custom.css" />

    <!-- Loading mathjax macro -->
    <!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"] ],
              displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
              processEscapes: true,
              processEnvironments: true
          },
          // Center justify equations in code and markdown cells. Elsewhere
          // we use CSS to left justify single line equations in code cells.
          displayAlign: 'center',
          "HTML-CSS": {
              styles: {'.MathJax_Display': {"margin": 0}},
              linebreaks: { automatic: true }
          }
      });
    </script>
    <!-- End of mathjax configuration -->
  </head>
  <body>
    <!-- ! custom navbar -->
    <div class="notebook-navbar">
      <a href="http://diegoinacio.github.io/machine-learning-notebooks/">
        Return to <span>Machine Learning Notebooks</span>
      </a>
    </div>
    <!-- /! custom navbar -->
    <div tabindex="-1" id="notebook" class="border-box-sizing">
      <div class="container" id="notebook-container">
        <div class="cell border-box-sizing text_cell rendered">
          <div class="prompt input_prompt"></div>
          <div class="inner_cell">
            <div class="text_cell_render border-box-sizing rendered_html">
              <h1 id="Polynomial-Regression">
                Polynomial Regression<a
                  class="anchor-link"
                  href="#Polynomial-Regression"
                  >¶</a
                >
              </h1>
              <hr />
              <ul>
                <li>Author: Diego Inácio</li>
                <li>
                  GitHub:
                  <a href="https://github.com/diegoinacio"
                    >github.com/diegoinacio</a
                  >
                </li>
                <li>
                  Notebook:
                  <a
                    href="https://github.com/diegoinacio/machine-learning-notebooks/blob/master/Machine-Learning-Fundamentals/regression_polynomial.ipynb"
                    >regression_polynomial.ipynb</a
                  >
                </li>
              </ul>
              <hr />
              <p>
                Overview and implementation of
                <em>Polynomial Regression</em> analysis.
              </p>
            </div>
          </div>
        </div>
        <div class="cell border-box-sizing code_cell rendered">
          <div class="input">
            <div class="prompt input_prompt">In&nbsp;[1]:</div>
            <div class="inner_cell">
              <div class="input_area">
                <div class="highlight hl-ipython3">
                  <pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">regression__utils</span> <span class="kn">import</span> <span class="o">*</span>
</pre>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="cell border-box-sizing text_cell rendered">
          <div class="prompt input_prompt"></div>
          <div class="inner_cell">
            <div class="text_cell_render border-box-sizing rendered_html">
              <p>Given the function:</p>
              $$ \large f(x)=x^3-3x^2+x+1+\epsilon $$
            </div>
          </div>
        </div>
        <div class="cell border-box-sizing code_cell rendered">
          <div class="input">
            <div class="prompt input_prompt">In&nbsp;[2]:</div>
            <div class="inner_cell">
              <div class="input_area">
                <div class="highlight hl-ipython3">
                  <pre><span></span><span class="c1"># Synthetic data 6</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">synthData6</span><span class="p">()</span>

<span class="c1"># Predicting with Linear Regression</span>
<span class="c1"># lrs = linearRegression_simple()</span>
<span class="c1"># lrs.fit(x, y)</span>
</pre>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="cell border-box-sizing text_cell rendered">
          <div class="prompt input_prompt"></div>
          <div class="inner_cell">
            <div class="text_cell_render border-box-sizing rendered_html">
              <p>
                <img
                  src="output/regression_polynomial_linear.png"
                  alt="polynomial data and linear regression"
                  title="Polynomial data and Linear Regression"
                />
              </p>
            </div>
          </div>
        </div>
        <div class="cell border-box-sizing text_cell rendered">
          <div class="prompt input_prompt"></div>
          <div class="inner_cell">
            <div class="text_cell_render border-box-sizing rendered_html">
              <h2 id="Algorithm">
                Algorithm<a class="anchor-link" href="#Algorithm">¶</a>
              </h2>
              <hr />
              $$ \large \vec{y}=\mathbf{X}\vec{\mathbf{\beta}}+\vec{\epsilon} $$
              <p>
                where $\large \mathbf{X}$ (or $\large \mathbf{V}$) is the
                <em>Vandermonde's matrix</em> of the independent variable,
                parametrised by the maximum degree $\large m$, a response vector
                $\large \vec{y}$, a parameter vector $\large
                \vec{\mathbf{\beta}}$ and a random error vector $\large
                \vec{\epsilon}$. In the form of a system of linear equations, we
                have:
              </p>
              $$ \large \begin{bmatrix} y_1 \\ y_2 \\ y_3 \\ \vdots \\ y_n
              \end{bmatrix} = \begin{bmatrix} 1 &amp; x_1 &amp; x_1^2
              &amp;\cdots &amp; x_1^m \\ 1 &amp; x_2 &amp; x_2^2 &amp; \cdots
              &amp; x_2^m \\ 1 &amp; x_3 &amp; x_3^2 &amp; \cdots &amp; x_3^m \\
              \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1
              &amp; x_n &amp; x_n^2 &amp; \cdots &amp; x_n^m \end{bmatrix}
              \begin{bmatrix} \beta_1 \\ \beta_2 \\ \beta_3 \\ \vdots \\ \beta_m
              \end{bmatrix} + \begin{bmatrix} \epsilon_1 \\ \epsilon_2 \\
              \epsilon_3 \\ \vdots \\ \epsilon_n \end{bmatrix} $$
              <p>
                By means of the Least Squares Method, the estimated coefficient
                vector is given by:
              </p>
              $$ \large
              \widehat{\vec{\mathbf{\beta}}}=(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\vec{y}
              $$
            </div>
          </div>
        </div>
        <div class="cell border-box-sizing code_cell rendered">
          <div class="input">
            <div class="prompt input_prompt">In&nbsp;[3]:</div>
            <div class="inner_cell">
              <div class="input_area">
                <div class="highlight hl-ipython3">
                  <pre><span></span><span class="k">def</span> <span class="nf">arraycast</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Decorador para conversão de vetores e matrizes</span>
<span class="sd">    '''</span>
    <span class="k">def</span> <span class="nf">wrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="p">[]):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">list</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wrap</span>

<span class="k">class</span> <span class="nc">polynomialRegression</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_degree</span> <span class="o">=</span> <span class="n">degree</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">beta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span>
    <span class="nd">@arraycast</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="p">[]):</span>
        <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">X</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">VTV</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
        <span class="n">VTV_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">VTV</span><span class="p">)</span>
        <span class="n">Vi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">VTV_i</span><span class="p">,</span> <span class="n">V</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Vi</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="nd">@arraycast</span>
    <span class="k">def</span> <span class="nf">pred</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span><span class="p">)</span>
</pre>
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="cell border-box-sizing text_cell rendered">
          <div class="prompt input_prompt"></div>
          <div class="inner_cell">
            <div class="text_cell_render border-box-sizing rendered_html">
              <p>
                Notice that our class has an attribute called
                <em>degree</em> which is the maximum degree of our function
                $\large f(x)$. In our example it should be $\large m=3$.
              </p>
            </div>
          </div>
        </div>
        <div class="cell border-box-sizing code_cell rendered">
          <div class="input">
            <div class="prompt input_prompt">In&nbsp;[4]:</div>
            <div class="inner_cell">
              <div class="input_area">
                <div class="highlight hl-ipython3">
                  <pre><span></span><span class="o">%%time</span>
<span class="n">polreg</span> <span class="o">=</span> <span class="n">polynomialRegression</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">polreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre>
                </div>
              </div>
            </div>
          </div>

          <div class="output_wrapper">
            <div class="output">
              <div class="output_area">
                <div class="prompt"></div>

                <div
                  class="output_subarea output_stream output_stdout output_text"
                >
                  <pre>
Wall time: 7.99 ms
</pre
                  >
                </div>
              </div>
            </div>
          </div>
        </div>
        <div class="cell border-box-sizing text_cell rendered">
          <div class="prompt input_prompt"></div>
          <div class="inner_cell">
            <div class="text_cell_render border-box-sizing rendered_html">
              <p>
                <img
                  src="output/regression_polynomial_pred.png"
                  alt="polynomial regression"
                  title="Polynomial Regression"
                />
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
